{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.7.0\n",
        "!pip install tensorflow-quantum==0.7.2"
      ],
      "metadata": {
        "id": "LskWFCPyZ0JP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update package resources to account for version changes.\n",
        "import importlib, pkg_resources\n",
        "importlib.reload(pkg_resources)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HglhrN8axSj",
        "outputId": "8cbd713b-4ddb-482d-9da8-d6aff63f371d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'pkg_resources' from '/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RL-nGEUYZjct"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_quantum as tfq\n",
        "\n",
        "import cirq\n",
        "import sympy\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import collections\n",
        "\n",
        "# visualization tools\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from cirq.contrib.svg import SVGCircuit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWRMIXh1ZsjS",
        "outputId": "6c02e4af-9bf7-4138-89f9-74d58c126933"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')"
      ],
      "metadata": {
        "id": "UnGWTFNnfZ4-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = test_images.reshape(test_images.shape[0], 28, 28, 1).astype('float32')"
      ],
      "metadata": {
        "id": "JFTBHOCJfmub"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rescale the images from [0,255] to the [0.0,1.0] range.\n",
        "x_train = (x_train - 127.5)/127.5  # Normalize the images to [-1, 1]\n",
        "x_test = (x_test - 127.5)/127.5  # Normalize the images to [-1, 1]\n",
        "\n",
        "print(\"Number of training examples:\", len(x_train))\n",
        "print(\"Number of test examples:\", len(x_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIbpQwi7bWHI",
        "outputId": "f270641f-5980-495d-994a-da1a23860575"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 60000\n",
            "Number of test examples: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_labels[0])\n",
        "\n",
        "plt.imshow(x_train[0, :, :, 0])\n",
        "plt.colorbar()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "mhiwFlCCbbYg",
        "outputId": "82cc4a50-163f-43bf-cbd4-f5b031fe959f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7f71937efe90>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATMAAAEDCAYAAABZIuPzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAZuUlEQVR4nO3dfZRddX3v8fcHEhJ5CJBGkjQ8BQSBCzrKCFxACRAUuasFbA3kWsVWiQWpQNVq4V4BW1ukaIneQh0hkrgsAcpTVotEgSpaCGSgEShRiBhqHkgIESLPmZnv/WPvoWfmzNmzJ+fMOWfv+bzWOmv22d/98OWIX35779/vtxURmJkV3XatTsDMrBFczMysFFzMzKwUXMzMrBRczMysFFzMzKwUXMzM6iRpgaSNkh5v0PF6Ja1IP0tGsN9Bkh6Q9Lqkz2VsN1PSg5JWSbpR0g7p+gnp91VpfN90/Ucq8lkhqU9SR73/nI0m9zMzq4+k9wEvAYsi4tAGHO+liNh5G/bbA9gHOA34TURcWWO7m4BbI2KxpH8EfhYR10g6F3hHRPyppDOB0yPijEH7HgbcHhH7jzS/0eaWmVmdIuI+YHPlOkn7S7pL0sOSfiLpoCbksTEilgNba20jScAJwD+nqxaSFD+AU9PvpPET0+0rzQUWNyzpBnIxMxsdXcCfRcThwOeAq0ew70RJ3ZKWSTpt+M1H5HeAFyKiJ/2+BpiRLs8Afg2Qxl9Mt690BnBDg3NqiHGtTsCsbCTtDBwN3FzRsJmQxj4EfHmI3dZGxAfS5X0iYq2k/YB7JT0WEb+U9LfA7w2x7+0R8X8a+09RTdKRwCsR0ZB7g43mYmbWeNuRtH6qbpJHxK3ArVk7R8Ta9O/Tkn4EvAv4ZUT8JfCXdeb2PLCbpHFp62tPYG0aWwvsBayRNA7YNd2+35m0aasMfJlp1nARsQX4laQPQ3KfStI78+wraXdJ/a24KcAxwBMNzC2AfwP+MF11FnBHurwk/U4avzfdHknbAXNo0/tl4KeZZnWTdAMwC5gCbAAuAe4FrgGmA+OBxREx1OXl4GMdDXwL6CNpbFwVEdflzGMa0A1MSvd/CTgkIrZIuhP4ZESsSy9fFwOTgf8A/igiXpc0EfguSUtwM3BmRDydHnsWcHlEHJUnl1ZwMTOzUvBlppmVQlMfAOygCTGRnZp5SrMx5TVe5o14fXDfsBH5wPE7xfObe3Nt+/Cjry+NiJPrOV+j1FXMJJ0MzAe2B66NiMuztp/IThypE+s5pZlleDDuqfsYz2/u5aGle+fadvvpT02p+4QNss3FTNL2wD8AJ5F0vFsuaUlENOzJi5k1XwB99LU6jRGrp2V2BLCq4mnHYpLhEC5mZgUWBFsj32VmO6mnmL059CG1Bjhy8EaS5gHzACayYx2nM7NmGWsts1wiootknBqTNNn9QMzaXBD0FrDLVj3FrH/oQ7/KYRFmVmB9jK1ithw4QNJMkiJ2JvC/G5KVmbVMAL1jqZhFRI+k84ClJF0zFkTEfzYsMzNrmbHWMiMi7gTubFAuZtYGAtg6xu6ZmVkJBTG2LjPNrKQCeotXy1zMzGygZARA8biYmdkgope6xqq3hIuZmQ2QPABwMTOzgkv6mbmYmVkJ9LllZmZF55aZmZVCIHoLOKO+i5mZVfFlppkVXiDeiO1bncaIuZiZ2QBJp1lfZppZCfgBgJkVXoToDbfMzKwE+twyM7OiSx4AFK80FC9jMxtVfgBgZqXR24R+ZpJuBN6eft0NeCEiOiTtAHwL6CSZjej8iPjRcMdzMTOzAZo1AiAizuhflvQ14MX069lp/DBJewDfl/SeiMicZs3FzMyq9DXxaaYkAXOAE9JVhwD3AkTERkkvkLTSHso6TvEujM1sVCUDzbfL9QGmSOqu+MzbhlO+F9gQEU+l338G/L6kcemrLA9n4Dt6h+SWmZkNEIit+YczbYqIzlpBSXcD04YIXRwRd6TLc4EbKmILgIOBbuAZ4H6gd7hEXMzMbIAIGtZpNiJmZ8UljQM+RNL66t+nB7iwYpv7gSeHO5eLmZkNomZ2mp0N/Dwi1rx5dmlHQBHxsqSTgJ6IeGK4A7mYmdkAQeNaZjmcycBLTIA9gKWS+oC1wEfzHMjFzMyqNGtyxoj4+BDrVvPf/c9yczEzswECeXJGMyu+5FVzxSsNxcvYzEaZXwJs7Wi77P5C4/aYMqqn/8XnZ9aM9e6YOTqFffbfmBnf6U+zz73+qgk1Y4903pi57296X8mMd97855nxt/35ssx4OwuaOwKgUeoqZpJWA78l6dDWk9V5zsyKY6y2zI6PiE0NOI6ZtYEIjb2WmZmVT/IAYOy9nSmAH0gK4FsR0TV4g3Tg6TyAiexY5+nMbPSNzXcAHBsRa9M5h34o6ecRcV/lBmmB6wKYpMlR5/nMbJQlDwCKd8+srvIbEWvTvxuB24AjGpGUmbXWCKYAahvbnI2knSTt0r8MvB94vFGJmVlr9I8AyPNpJ/VcZk4FbksmiWQc8E8RcVdDsiqZ7d/+tsx4vGWHzPi643bLjL961Ms1Y5N3rR0D+Pd33pQZb6W7Xs2+x/o3V5+SGV9+2ODxy//tv3qy+5F95dmTMuO/+5Ny3zEZUy80iYingXc2MBczawMRsLVvDBUzMyun5DLTxczMSmCsjgAwsxIpatcMFzMzG8SXmWZWEk18B0DDuJg1QO+sd2fGr7r+/2XGDxw/sZHpFEbPMG8Pu/gbf5IZH/dydveII2/+dM3YLmt7MvedsOnVzPiO3Q9mxosseZo59sZmmlnJeNpsMysNX2aaWeH5aaaZlYafZppZ4UWIHhczMysDX2aaWeH5ntkYNuHnazPjy1/bOzN+4PjsV6q10oXrj8yMP/1S9qvqvrv/LTVjL/Rlv2pu6jfuz4yPpnJP8DO8ZhQzSR3APwITgR7g3Ih4SMm8YvOBU4BXgI9HxCPDHa94F8ZmNqqaODnjFcBlEdEBfCn9DvBB4ID0Mw+4Js/BXMzMrEofyvWpUwCT0uVdgXXp8qnAokgsA3aTNH24g/ky08wGiICe/JMzTpHUXfG9a6i3tNVwAbBU0pUkDauj0/UzgF9XbLcmXbc+62AuZmZWZQSXkJsiorNWUNLdwLQhQhcDJwIXRsQtkuYA1wGzR5prPxczMxugkWMzI6JmcZK0CDg//XozcG26vBbYq2LTPdN1mXzPzMyqRCjXp07rgOPS5ROAp9LlJcDHlDgKeDEiMi8xwS0zMxtCkwaanw3MlzQOeI3kySXAnSTdMlaRdM344zwHczFrgJ5nN2TGv/nVD2fGv3Jy9uvgtn9058z4Y+dmz5eW5cubDsuMrzrhLZnx3i3Z/8E843+eUzO2+jOZuzKTn2VvYKMiojn9zCLip8DhQ6wPoPZkdDW4mJnZIKLXr5ozszJowP2wpnMxM7MBPDbTzMohkvtmReNiZmZVPG22mRVe+AGAmZWFLzNtSJO/80Bm/K1LJmfGe5/fnBk/+NDafQpXvu87mfsu6TouM77HlvrmFNMDtfuKzcz+WayFivg0c9i2pKQFkjZKerxi3WRJP5T0VPp399FN08yaJaJpw5kaKs+F8fXAyYPWfRG4JyIOAO5Jv5tZSTRpcsaGGraYRcR9wODrnFOBhenyQuC0BudlZi0Uke/TTrb1ntnUilHszwJTa20oaR7pANKJ7LiNpzOzZglEXwGfZtadcTootGaNjoiuiOiMiM7xTKj3dGbWBJHz0062tZht6J+TO/3bvq8XMrORKfEDgKEsAc5Kl88C7mhMOmbWFgrYNBv2npmkG4BZJC8uWANcAlwO3CTpE8AzwJzRTLLshutHNpytW3bY5n3/x0eeyIw/d/Uw//Vtt7vA1hDt1urKY9hiFhFza4RObHAuZtYGAujrK2ExM7MxJoAytszMbOwp4t0DFzMzq+ZiZmbF137dLvJwMTOzam6ZWSsc/Plf1IydddgJmfsu3OfezPh755ybGd/lxmWZcSuggPDTTDMrBxczMysDX2aaWSm4mJlZ4RW002zxJi0ys1HXjMkZJXVIWiZphaRuSUek6w+S9ICk1yV9Lu/x3DIzs2rNeZp5BXBZRHxf0inp91kkM1t/hhHOYO2WmZlVUeT71CmASenyrsA6gIjYGBHLga0jOZhbZiXQu2VLzdjz5xycue9/LXklM37xV67PjP/FnD/IjMd/7Fozttdf1/caOxslI5urbIqk7orvXRHRlXPfC4Clkq4kaVgdnfusQ3AxM7NBNJIHAJsiorPmkaS7gWlDhC4mmUbswoi4RdIc4Dpg9kiz7ediZmbVGtQ1IyJqFidJi4Dz0683A9fWcy7fMzOzan05P/VZBxyXLp8APFXPwdwyM7OBmtfP7GxgvqRxwGukr6SUNA3oJnk40CfpAuCQiKh9cxgXMzMbQgOeVA4rIn4KHD7E+meBPUd6PBczM6tWwOFMvmdmZqXgllnJ9f1sZWZ8zmWfz4wvvuTvMuOPHvXd7ASOqh06eKdPZ+56QNe6zHjPr57JPrdts2ZcZjaai5mZDRQ0azhTQ7mYmVk1t8zMrAx8mWlm5eBiZmal4GJmZkXXoOl9ms7FzMyq+WmmFc3kBQ9kxs/5xXmZ8UmXr8mM37jfD2rGVn7sHzL3PXCvT2TG335pdp/v3lW/yoxbbUVsmQ07AkDSAkkbJT1ese5SSWvTubtXpFPemllZRM5PG8kznOl64OQh1v99RHSknzsbm5aZtUzOKbPbrfU2bDGLiPtIXjBgZmNFSVtmtZwn6dH0MnT3WhtJmpe+Rqp7K6/XcTozaxb15fu0k20tZtcA+wMdwHrga7U2jIiuiOiMiM7xTNjG05mZZdumYhYRGyKiNyL6gG8DRzQ2LTNrqbFymSlpesXX04HHa21rZgVT0AcAw/Yzk3QDyVuGp0haA1wCzJLUQVKbVwOfGsUcrYX07ysy46986K2Z8cPn1u6ntvwL38zc98njr8uMz933pMz4i8dmhi1LmxWqPIYtZhExd4jV2f+WmVmxlbGYmdnYItrvSWUeLmZmNlAb3g/Lw8XMzKq5mJlZKbiYmVkZ+DLTxpze557LjE/9Ru3463+xNXPft2iHzPiCff81M/7B08+vGdvxtgcz9x3zCljM/BJgMxsomjM2U1KHpGXpNGLdko5I138kHff9mKT7Jb0zz/FczMysWnOGM10BXBYRHcCX0u8AvwKOi4jDgL8CuvIczJeZZlalSffMApiULu8KrAOIiPsrtlkG7JnnYC5mZlYtfzGbIqm74ntXRORqSQEXAEslXUlylXj0ENt8Avh+noO5mJnZQCO7hNwUEZ21gpLuBqYNEboYOBG4MCJukTSHZJjk7Ip9jycpZrlG2bqYmdkAonGXmRExu1ZM0iKg/5HzzcC1FbF3pN8/GBHP5zmXHwCYWZUmTQG0DjguXT4BeApA0t7ArcBHI+LJvAdzy8wy9R3bkRn/5YcnZsYP7VhdMzZcP7LhXLU5O7cdb3+oruOPac15AHA2MF/SOOA1YF66/kvA7wBXSwLoybqU7ediZmbVmlDMIuKnwOFDrP8k8MmRHs/FzMwG8qwZZlYaLmZmVgaenNHMSsGXmWZWfG34Grk8XMzMrJqLmbUbdR6aGX/yM8PMGXbM9Znx907sGWlKub0e2cdetnlm9gFifQOzGTsaOQKgmVzMzKyK+opXzVzMzGwg3zMzs7LwZaaZlYOLmZmVgVtmZlYOLmZmVnhR0uFMkvYCFgFTSep1V0TMlzQZuBHYF1gNzImI34xeqmPXuH33zoz/8k9m1IxdesbizH0/vHOuSTxHxRc3VM3+MsCP5x+VGd994QONTMdSRe1nlmem2R7gsxFxCHAU8GlJhwBfBO6JiAOAe9LvZlYGEfk+bWTYYhYR6yPikXT5t8BKYAZwKrAw3WwhcNpoJWlmzdWkabMbakT3zCTtC7wLeBCYGvHmeJFnSS5Dzazoyt5pVtLOwC3ABRGxJZ2bG4CICGnoOi1pHunc3hPZsb5szawpivgAINfbmSSNJylk34uIW9PVGyRNT+PTgY1D7RsRXRHRGRGd45nQiJzNbJSpL9+nnQxbzJQ0wa4DVkbE1ytCS4Cz0uWzgDsan56ZNV1QyAcAeS4zjwE+CjwmaUW67iLgcuAmSZ8AngHmjE6KxTdun70y4y92/m5m/Iwv35UZP3e320ecU6NcuP7IzPgDV9d+Q9jk7yzL3Hf3cNeLVmm3m/t5DFvM0tdBqUb4xMamY2ZtoYzFzMzGlqJ2mnUxM7OBIjw5o5mVRPFqWb6uGWY2tjRjBICkDknLJK2Q1C3piHT9qZIerVh/bJ7juWVmZgMF0JzLzCuAyyLi+5JOSb/PIhnrvSTtjP8O4CbgoOEO5mJmZtWac5kZwKR0eVdgHUBEvFSxzU55s3Exy2nctNpDTzd/Z+fMfc+Z+ePM+Ed2GXLwRFOcu/aYzPgj13Rkxqfc9GhmfPLL7itWRCO4hJwiqbvie1dEdOXc9wJgqaQrSW55Hf3m+aXTgb8F9gD+V56DuZiZWZURPM3cFBE1e0ZLuhuYNkToYpJ+qhdGxC2S5pCMNJoNEBG3AbdJeh/wV/3rs7iYmdlADZw1IyJqFiFJi4Dz0683A9cOsf99kvaTNCUiNmWdy08zzWyApNNs5PrUaR1wXLp8AvAUgKS3pWPCkfRuYAIw7JTIbpmZWbXmzIhxNjBf0jjgNdKpwoA/AD4maSvwKnBGxPCV08XMzKo0oNU1rHTcd9WLICLiq8BXR3o8FzMzG6jsM82a2VjhsZlt7Y0P1J5XC+CNCzdnxv/v2/61Zuykt7y6TTk1ysbeV2rGjlny2cx9D7poZWZ88pbsfmJtNtmoNUqbTbyYx5gpZmaWU1lfAmxmY5BbZmZWCsWrZS5mZlZNfcW7znQxM7OBgkI+2XExM7MBREOGKjWdi5mZVXMxa1+rT8seU7/qsH8etXN/84X9MuPzf/z+zLh6a73pL3HQl5+uGTvguQcz9+3NjNqY5WJmZoXne2ZmVhZ+mmlmJRC+zDSzEghczMysJIp3leliZmbV3M/MzMqhjMVM0l7AImAqydV0V0TMl3QpyRzez6WbXhQRd45WovU68JyHMuOnnPPuJmVS7UCycxuO+4pZQ0VAb/GuM/O0zHqAz0bEI5J2AR6W9MM09vcRceXopWdmLVHGlllErAfWp8u/lbQSmDHaiZlZCxWwmI3ovZmS9gXeBfSPkTlP0qOSFkjavcY+8yR1S+reyut1JWtmTRBAX+T7tJHcxUzSzsAtwAURsQW4Btgf6CBpuX1tqP0ioisiOiOiczwTGpCymY2ugOjL92kjuZ5mShpPUsi+FxG3AkTEhor4t4F/GZUMzay5gkI+ABi2ZZa+Jv06YGVEfL1i/fSKzU4HHm98embWEhH5Pm0kT8vsGOCjwGOSVqTrLgLmSuogqeOrgU+NSoZm1nxtVqjyyPM086fAUBNqtW2fMjOrR/u1uvIY0dNMMxsDAujry/epg6QOScskrUh7PBwxKP4eST2S/jDP8VzMzKxac+6ZXQFcFhEdwJfS7wBI2h74KvCDvAfz2EwzG6Rpw5kCmJQu7wqsq4j9GUkPivfkPZiLmZkNFBD5+5BNkdRd8b0rIrpy7nsBsFTSlSRXiUcDSJpB0kPieFzMzKwu+Xv3b4qIzlpBSXcD04YIXQycCFwYEbdImkPSBWw2cBXwhYjoS3qG5eNiZmbVGvQ0MyJm14pJWgScn369Gbg2Xe4EFqeFbApwiqSeiLg961wuZmY2UETdTypzWgccB/wIOAF4Kjl9zOzfQNL1wL8MV8jAxczMhtKcfmZnA/MljQNeA+bVczAXMzMbJIje0Z/yM+2Qf/gw23w87/FczMxsoP4pgArGxczMqrXZ9D55uJiZ2QABhFtmZlZ4EW6ZmVk5NOMBQKMpmjjVh6TngGcqVk0BNjUtgZFp19zaNS9wbtuqkbntExFvrecAku4iySmPTRFxcj3na5SmFrOqk0vdWUMhWqldc2vXvMC5bat2zq1IPAWQmZWCi5mZlUKri1neqUJaoV1za9e8wLltq3bOrTBaes/MzKxRWt0yMzNrCBczMyuFlhQzSSdL+oWkVZK+2IocapG0WtJj/W+MaXEuCyRtlPR4xbrJkn4o6an07+5tlNulktamv90KSae0KLe9JP2bpCck/aek89P1Lf3tMvJqi9+t6Jp+zyx968qTwEnAGmA5MDcinmhqIjVIWg10RkTLO1hKeh/wErAoIg5N110BbI6Iy9P/EOweEV9ok9wuBV6KiCubnc+g3KYD0yPiEUm7AA8DpwEfp4W/XUZec2iD363oWtEyOwJYFRFPR8QbwGLg1Bbk0fYi4j5g86DVpwIL0+WFJP9naLoaubWFiFgfEY+ky78FVgIzaPFvl5GXNUAritkM4NcV39fQXv+DBvADSQ9Lqmvmy1EyNSLWp8vPAlNbmcwQzpP0aHoZ2pJL4EqS9gXeBTxIG/12g/KCNvvdisgPAKodGxHvBj4IfDq9nGpLkdwjaKe+NdcA+wMdwHrga61MRtLOJO9evCAitlTGWvnbDZFXW/1uRdWKYrYW2Kvi+57purYQEWvTvxuB20gui9vJhvTeS/89mI0tzudNEbEhInojeenit2nhbydpPEnB+F5E3JqubvlvN1Re7fS7FVkritly4ABJMyXtAJwJLGlBHlUk7ZTemEXSTsD7gcez92q6JcBZ6fJZwB0tzGWA/kKROp0W/XZK3lF2HbAyIr5eEWrpb1crr3b53YquJSMA0kfPVwHbAwsi4itNT2IIkvYjaY1BMtfbP7UyN0k3ALNIpmPZAFwC3A7cBOxNMp3SnIho+o34GrnNIrlUCmA18KmKe1TNzO1Y4CfAY0D/LIMXkdyfatlvl5HXXNrgdys6D2cys1LwAwAzKwUXMzMrBRczMysFFzMzKwUXMzMrBRczMysFFzMzK4X/D9tANROUNT1eAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downscaling the images \n",
        "Because the size 28 x 28 is too large for current quantum computers. So the image needs to be resized to 4 x 4."
      ],
      "metadata": {
        "id": "YnQRPl0ncGJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_small = tf.image.resize(x_train, (4,4)).numpy()\n",
        "x_test_small = tf.image.resize(x_test, (4,4)).numpy()"
      ],
      "metadata": {
        "id": "rSMMGzdObnLA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_labels[0])\n",
        "plt.imshow(x_train_small[0,:,:,0], vmin=0, vmax=1)\n",
        "plt.colorbar()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "YMee9Wnpc8V1",
        "outputId": "aa0eab98-d2d0-4c73-d38e-de4e383dc5ad"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7febee62ea10>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encode data as quantum circuit\n",
        "Each pixel with a qubit, state depending on the value of the pixel. \n",
        "First step, converting to a binary encoding."
      ],
      "metadata": {
        "id": "T6S0JJMBhZ9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "THRESHOLD = 0.5\n",
        "\n",
        "x_train_bin = np.array(x_train_small > THRESHOLD, dtype=np.float32)\n",
        "x_test_bin = np.array(x_test_small > THRESHOLD, dtype=np.float32)"
      ],
      "metadata": {
        "id": "oaH2GoIggepv"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_circuit(image):\n",
        "    \"\"\"Encode truncated classical image into quantum datapoint.\"\"\"\n",
        "    values = np.ndarray.flatten(image)\n",
        "    qubits = cirq.GridQubit.rect(4, 4)\n",
        "    circuit = cirq.Circuit()\n",
        "    for i, value in enumerate(values):\n",
        "        if value:\n",
        "            circuit.append(cirq.X(qubits[i]))\n",
        "    return circuit\n",
        "\n",
        "\n",
        "x_train_circ = [convert_to_circuit(x) for x in x_train_bin]\n",
        "x_test_circ = [convert_to_circuit(x) for x in x_test_bin]"
      ],
      "metadata": {
        "id": "ln0ZCBn5hqja"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The circuit created for the first example (circuit diagrams do not show qubits with zero gates):"
      ],
      "metadata": {
        "id": "q2BxfAaAiK0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SVGCircuit(x_train_circ[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "A1hoBaFxiC4B",
        "outputId": "4d44d746-22d0-4840-d1ff-d987f9918443"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.font_manager:findfont: Font family ['Arial'] not found. Falling back to DejaVu Sans.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<cirq.contrib.svg.svg.SVGCircuit at 0x7febee5fbf90>"
            ],
            "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"169.517734375\" height=\"100.0\"><line x1=\"34.7588671875\" x2=\"139.517734375\" y1=\"25.0\" y2=\"25.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"34.7588671875\" x2=\"139.517734375\" y1=\"75.0\" y2=\"75.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><rect x=\"10.0\" y=\"5.0\" width=\"49.517734375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"34.7588671875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(2, 2): </text><rect x=\"10.0\" y=\"55.0\" width=\"49.517734375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"34.7588671875\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(3, 1): </text><rect x=\"79.517734375\" y=\"5.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"99.517734375\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"79.517734375\" y=\"55.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"99.517734375\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text></svg>"
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above circuit can be more easily understood by the looking at the image below, and comparing the positions of the image values which have exceeded the threshold value:"
      ],
      "metadata": {
        "id": "V333MChBivW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bin_img = x_train_bin[0,:,:,0]\n",
        "plt.imshow(bin_img)\n",
        "indices = np.array(np.where(bin_img)).T\n",
        "indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "AZvEOgSIiJF7",
        "outputId": "bfeb85a9-e68e-4d33-eeac-69bd2250e7f5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2, 2],\n",
              "       [3, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert the ```Cirq``` circuits to tensors for tfq :"
      ],
      "metadata": {
        "id": "VRz_pTAOiev5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_tfcirc = tfq.convert_to_tensor(x_train_circ)\n",
        "x_test_tfcirc = tfq.convert_to_tensor(x_test_circ)"
      ],
      "metadata": {
        "id": "vxU7s2-QiZYJ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quantum Neural Network"
      ],
      "metadata": {
        "id": "OToBvvBNjACF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CircuitLayerBuilder():\n",
        "    def __init__(self, data_qubits, readout):\n",
        "        self.data_qubits = data_qubits\n",
        "        self.readout = readout\n",
        "\n",
        "    def add_layer(self, circuit, gate, prefix):\n",
        "        for i, qubit in enumerate(self.data_qubits):\n",
        "            symbol = sympy.Symbol(prefix + '-' + str(i))\n",
        "            circuit.append(gate(qubit, self.readout)**symbol)"
      ],
      "metadata": {
        "id": "sNKOpJt6im-t"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo_builder = CircuitLayerBuilder(data_qubits = cirq.GridQubit.rect(4,1),\n",
        "                                   readout=cirq.GridQubit(-1,-1))\n",
        "\n",
        "circuit = cirq.Circuit()\n",
        "demo_builder.add_layer(circuit, gate = cirq.XX, prefix='xx')\n",
        "SVGCircuit(circuit)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "hiTGbZTXjRxZ",
        "outputId": "92dd4b9b-63d7-4300-b86a-bda6bb8338a1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<cirq.contrib.svg.svg.SVGCircuit at 0x7febc3c99c90>"
            ],
            "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"522.59953125\" height=\"250.0\"><line x1=\"39.810625\" x2=\"492.59953125000004\" y1=\"25.0\" y2=\"25.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"492.59953125000004\" y1=\"75.0\" y2=\"75.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"492.59953125000004\" y1=\"125.0\" y2=\"125.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"492.59953125000004\" y1=\"175.0\" y2=\"175.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"492.59953125000004\" y1=\"225.0\" y2=\"225.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"129.99353515625\" x2=\"129.99353515625\" y1=\"25.0\" y2=\"75.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"230.73810546875004\" x2=\"230.73810546875004\" y1=\"25.0\" y2=\"125.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"331.48267578125007\" x2=\"331.48267578125007\" y1=\"25.0\" y2=\"175.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"432.22724609375007\" x2=\"432.22724609375007\" y1=\"25.0\" y2=\"225.0\" stroke=\"black\" stroke-width=\"3\" /><rect x=\"10.0\" y=\"5.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(-1, -1): </text><rect x=\"10.0\" y=\"55.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 0): </text><rect x=\"10.0\" y=\"105.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(1, 0): </text><rect x=\"10.0\" y=\"155.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(2, 0): </text><rect x=\"10.0\" y=\"205.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(3, 0): </text><rect x=\"89.62125\" y=\"55.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"129.99353515625\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^(xx-0)</text><rect x=\"89.62125\" y=\"5.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"129.99353515625\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"190.36582031250003\" y=\"105.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"230.73810546875004\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^(xx-1)</text><rect x=\"190.36582031250003\" y=\"5.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"230.73810546875004\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"291.11039062500004\" y=\"155.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"331.48267578125007\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^(xx-2)</text><rect x=\"291.11039062500004\" y=\"5.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"331.48267578125007\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"391.85496093750004\" y=\"205.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"432.22724609375007\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^(xx-3)</text><rect x=\"391.85496093750004\" y=\"5.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"432.22724609375007\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text></svg>"
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_quantum_model():\n",
        "    \"\"\"Create a QNN model circuit and readout operation to go along with it.\"\"\"\n",
        "    data_qubits = cirq.GridQubit.rect(4, 4)  # a 4x4 grid.\n",
        "    readout = cirq.GridQubit(-1, -1)         # a single qubit at [-1,-1]\n",
        "    circuit = cirq.Circuit()\n",
        "\n",
        "    # Prepare the readout qubit.\n",
        "    circuit.append(cirq.X(readout))\n",
        "    circuit.append(cirq.H(readout))\n",
        "\n",
        "    builder = CircuitLayerBuilder(\n",
        "        data_qubits = data_qubits,\n",
        "        readout=readout)\n",
        "\n",
        "    # Then add layers (experiment by adding more).\n",
        "    builder.add_layer(circuit, cirq.XX, \"xx1\")\n",
        "    builder.add_layer(circuit, cirq.ZZ, \"zz1\")\n",
        "\n",
        "    # Finally, prepare the readout qubit.\n",
        "    circuit.append(cirq.H(readout))\n",
        "\n",
        "    return circuit, cirq.Z(readout)"
      ],
      "metadata": {
        "id": "933yA7cLjUHf"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_circuit, model_readout = create_quantum_model()"
      ],
      "metadata": {
        "id": "tU7MN7mbjmLb"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wrapping the model in the tfq-keras model"
      ],
      "metadata": {
        "id": "kDJ06Q9ijrth"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the Keras model.\n",
        "model = tf.keras.Sequential([\n",
        "    # The input is the data-circuit, encoded as a tf.string\n",
        "    tf.keras.layers.Input(shape=(), dtype=tf.string),\n",
        "    # The PQC layer returns the expected value of the readout gate, range [-1,1].\n",
        "    tfq.layers.PQC(model_circuit, model_readout),\n",
        "])"
      ],
      "metadata": {
        "id": "KkDZn_-Fjn2m"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels_hinge = 2.0*train_labels-1.0\n",
        "test_labels_hinge = 2.0*test_labels-1.0"
      ],
      "metadata": {
        "id": "5HERq_ENjxGG"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hinge_accuracy(y_true, y_pred):\n",
        "    y_true = tf.squeeze(y_true) > 0.0\n",
        "    y_pred = tf.squeeze(y_pred) > 0.0\n",
        "    result = tf.cast(y_true == y_pred, tf.float32)\n",
        "\n",
        "    return tf.reduce_mean(result)"
      ],
      "metadata": {
        "id": "W2AwVLh9kAy8"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss=tf.keras.losses.Hinge(),\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    metrics=[hinge_accuracy])\n",
        "\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z18Hb-vXkMZw",
        "outputId": "a64a7842-468a-44a9-a226-c6cef04573c3"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " pqc (PQC)                   (None, 1)                 32        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 32\n",
            "Trainable params: 32\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "KADuVhkYhmdF",
        "outputId": "dae120f4-8f30-45e4-ca59-e8424a62049b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/util.py:1345: NameBasedSaverStatus.__init__ (from tensorflow.python.training.tracking.util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-656266d79a7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/weights.index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36massert_consumed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1021\u001b[0m       raise AssertionError(\n\u001b[1;32m   1022\u001b[0m           \"Some objects had attributes which were not restored:{}\".format(\n\u001b[0;32m-> 1023\u001b[0;31m               \"\".join(unused_attribute_strings)))\n\u001b[0m\u001b[1;32m   1024\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtrackable\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Some objects had attributes which were not restored:\n    <tf.Variable 'parameters:0' shape=(32,) dtype=float32, numpy=\narray([3.2600942 , 0.27192506, 2.63036   , 2.98352   , 1.2158424 ,\n       3.3558767 , 2.2835326 , 0.736734  , 4.841832  , 4.4579754 ,\n       0.2900355 , 0.4038804 , 4.236371  , 4.0680633 , 6.252827  ,\n       3.43102   , 2.6101844 , 0.04220095, 0.7914892 , 6.13759   ,\n       2.0362623 , 0.15416057, 4.944003  , 2.1335554 , 3.3619955 ,\n       0.45097688, 5.964427  , 3.6705966 , 4.1898785 , 3.9264321 ,\n       5.502196  , 0.14368112], dtype=float32)>: ['parameters']"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TRAIN THE MODEL"
      ],
      "metadata": {
        "id": "StEuVPrJkeId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 3\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "NUM_EXAMPLES = len(x_train_tfcirc)"
      ],
      "metadata": {
        "id": "nonvWmJ2kPad"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_tfcirc_sub = x_train_tfcirc[:NUM_EXAMPLES]\n",
        "train_labels_hinge_sub = train_labels_hinge[:NUM_EXAMPLES]"
      ],
      "metadata": {
        "id": "1BqmiV-skgYN"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qnn_history = model.fit(\n",
        "      x_train_tfcirc_sub, train_labels_hinge_sub,\n",
        "      batch_size=32,\n",
        "      epochs=EPOCHS,\n",
        "      verbose=1,\n",
        "      validation_data=(x_test_tfcirc, test_labels_hinge))\n",
        "\n",
        "qnn_results = model.evaluate(x_test_tfcirc, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRwLpWJjkrEy",
        "outputId": "cc595300-6006-418e-9f94-d36ad6309db7"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "1875/1875 [==============================] - 3479s 2s/step - loss: 0.2142 - hinge_accuracy: 0.8970 - val_loss: 0.1607 - val_hinge_accuracy: 0.9020\n",
            "Epoch 2/3\n",
            "1875/1875 [==============================] - 3455s 2s/step - loss: 0.1595 - hinge_accuracy: 0.9012 - val_loss: 0.1541 - val_hinge_accuracy: 0.9020\n",
            "Epoch 3/3\n",
            "1875/1875 [==============================] - 3428s 2s/step - loss: 0.1582 - hinge_accuracy: 0.9012 - val_loss: 0.1529 - val_hinge_accuracy: 0.9020\n",
            "313/313 [==============================] - 99s 314ms/step - loss: 0.1127 - hinge_accuracy: 0.9020\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('QDiscriminator_ModelWeights')\n",
        "print('Model Saved!')\n",
        " \n",
        "# load model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyr_BBGjMPvj",
        "outputId": "95a17dee-3e45-4228-9bff-1734316fb406"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "savedModel = model.load_weights('QDiscriminator_ModelWeights')\n",
        "print('Model Loaded!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTrWoMwAMjd6",
        "outputId": "0bbd2eec-031a-4000-f188-10a99c5481a4"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Loaded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save('QDiscriminator_v1.h5')\n",
        "# print('Model Saved!')\n",
        "savedModel=load_model('QDiscriminator_v1.h5')\n",
        "savedModel.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "icyUaAifLuPb",
        "outputId": "d89a021d-8937-4d4e-8c06-ab1d6182beeb"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-b38451ad89b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# model.save('QDiscriminator_v1.h5')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# print('Model Saved!')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msavedModel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'QDiscriminator_v1.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0msavedModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_config'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel_config\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'No model config found in the file at {filepath}.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'decode'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m       \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No model config found in the file at QDiscriminator_v1.h5."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the weights using the `checkpoint_path` format\n",
        "path = 'weights_folder/weights'\n",
        "model.save_weights(path)"
      ],
      "metadata": {
        "id": "eCKg8HKmk0_a"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qvwb-6DWfI0j"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classical Neural Network"
      ],
      "metadata": {
        "id": "O0l-3ZHdWZx6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_classical_model():\n",
        "    # A simple model based off LeNet from https://keras.io/examples/mnist_cnn/\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Conv2D(32, [3, 3], activation='relu', input_shape=(28,28,1)))\n",
        "    model.add(tf.keras.layers.Conv2D(64, [3, 3], activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(tf.keras.layers.Dropout(0.25))\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dropout(0.5))\n",
        "    model.add(tf.keras.layers.Dense(1))\n",
        "    return model\n",
        "\n",
        "\n",
        "model1 = create_classical_model()\n",
        "model1.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gX3IYI1ZVCEC",
        "outputId": "75dfce3d-6126-4d1c-df59-dd619b7677a5"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 24, 24, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 12, 12, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 12, 12, 64)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 9216)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               1179776   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,198,721\n",
            "Trainable params: 1,198,721\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.fit(x_train,\n",
        "          train_labels,\n",
        "          batch_size=128,\n",
        "          epochs=1,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, test_labels))\n",
        "\n",
        "cnn_results = model1.evaluate(x_test, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zy5f6RmjWkHZ",
        "outputId": "7dfa664e-bfa1-4029-f678-74d9d88aa67d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "469/469 [==============================] - 5s 9ms/step - loss: -677931328.0000 - accuracy: 0.1124 - val_loss: -3624126976.0000 - val_accuracy: 0.1135\n",
            "313/313 [==============================] - 1s 3ms/step - loss: -3624126208.0000 - accuracy: 0.1135\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cktgvbF7WnU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combining the classical generator with quantum discriminator"
      ],
      "metadata": {
        "id": "RR6--4pjWQ53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_generator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    #experiment with use_bias = True\n",
        "    model.add(tf.keras.layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.LeakyReLU())\n",
        "\n",
        "    model.add(tf.keras.layers.Reshape((7, 7, 256)))\n",
        "    assert model.output_shape == (None, 7, 7, 256)  # Note: None is the batch size\n",
        "\n",
        "    #use use_bias = True\n",
        "    model.add(tf.keras.layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 7, 7, 128)\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.LeakyReLU())\n",
        "\n",
        "    #use use_bias = True\n",
        "    model.add(tf.keras.layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 14, 14, 64)\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.LeakyReLU())\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 28, 28, 1)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "4mBTnOQ3WQiT"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = make_generator_model()\n",
        "\n",
        "noise = tf.random.normal([1,100])\n",
        "generated_image = generator(noise, training=False)\n",
        "\n",
        "plt.imshow(generated_image[0,:,:,0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "tIEd8EmOWeA1",
        "outputId": "e6c1d93c-c9c2-413c-c156-bedf83108141"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ff6482b1bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "88a1ZFW1fiI_"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "metadata": {
        "id": "IPRNYnOSWn4R"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss"
      ],
      "metadata": {
        "id": "DbLUfY2OfQFH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
      ],
      "metadata": {
        "id": "uJTxolCwfS8W"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
      ],
      "metadata": {
        "id": "JJ5ofTLSfWC8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SAVE CHECKPOINT FUNCTION\n",
        "import os\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=model)"
      ],
      "metadata": {
        "id": "7W7Ic9HxfYZ6"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 50\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 16\n",
        "\n",
        "# You will reuse this seed overtime (so it's easier)\n",
        "# to visualize progress in the animated GIF)\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
      ],
      "metadata": {
        "id": "FNWYCEsbfbZ7"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Notice the use of `tf.function`\n",
        "# This annotation causes the function to be \"compiled\".\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_images = generator(noise, training=True)\n",
        "\n",
        "      real_output = model(images, training=True)\n",
        "      fake_output = model(generated_images, training=True)\n",
        "\n",
        "      gen_loss = generator_loss(fake_output)\n",
        "      disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, model.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, model.trainable_variables))"
      ],
      "metadata": {
        "id": "ChQjS9OqO9Ug"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_save_images(model, epoch, test_input):\n",
        "  # Notice `training` is set to False.\n",
        "  # This is so all layers run in inference mode (batchnorm).\n",
        "  predictions = model(test_input, training=False)\n",
        "\n",
        "  fig = plt.figure(figsize=(4, 4))\n",
        "\n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.subplot(4, 4, i+1)\n",
        "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "      plt.axis('off')\n",
        "\n",
        "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "dao7j5tXO_6W"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    for image_batch in dataset:\n",
        "      train_step(image_batch)\n",
        "\n",
        "    # Produce images for the GIF as you go\n",
        "    display.clear_output(wait=True)\n",
        "    generate_and_save_images(generator,\n",
        "                             epoch + 1,\n",
        "                             seed)\n",
        "\n",
        "    # Save the model every 15 epochs\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "  # Generate after the final epoch\n",
        "  display.clear_output(wait=True)\n",
        "  generate_and_save_images(generator,\n",
        "                           epochs,\n",
        "                           seed)"
      ],
      "metadata": {
        "id": "aCG7iCChPCrr"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch and shuffle the data\n",
        "BUFFER_SIZE = 60000 #equal to the number of images in the whole dataset\n",
        "BATCH_SIZE = 256 #\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images)\n",
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "bgCOOsA5PQS0"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(x_train_small, EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UVWBP6w1PFks",
        "outputId": "5fc9debe-df91-46e3-fcfc-1585dc751c17"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None,) for input KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.string, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (4, 4, 1).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-5ecec92d0977>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_small\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-61-bc60a43fa1e9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataset, epochs)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimage_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m       \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Produce images for the GIF as you go\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"<ipython-input-59-0e8a787cefd5>\", line 10, in train_step  *\n        real_output = model(images, training=True)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer \"pqc\" (type PQC).\n    \n    in user code:\n    \n        File \"/usr/local/lib/python3.7/dist-packages/tensorflow_quantum/python/layers/high_level/pqc.py\", line 299, in call  *\n            model_appended = self._append_layer(inputs, append=tiled_up_model)\n        File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n    \n        ValueError: Exception encountered when calling layer \"add_circuit\" (type AddCircuit).\n        \n        in user code:\n        \n            File \"/usr/local/lib/python3.7/dist-packages/tensorflow_quantum/python/layers/circuit_construction/elementary.py\", line 128, in call  *\n                return tfq_utility_ops.append_circuit(inputs, append)\n            File \"/usr/local/lib/python3.7/dist-packages/tensorflow_quantum/core/ops/tfq_utility_ops.py\", line 65, in append_circuit  *\n                return UTILITY_OP_MODULE.tfq_append_circuit(programs, programs_to_append)\n            File \"<string>\", line 75, in tfq_append_circuit  **\n                \n        \n            ValueError: Shape must be rank 1 but is rank 3 for '{{node sequential_1/pqc/add_circuit/TfqAppendCircuit}} = TfqAppendCircuit[](sequential_1/Cast, sequential_1/pqc/Tile)' with input shapes: [4,4,1], [4].\n        \n        \n        Call arguments received:\n          • inputs=tf.Tensor(shape=(4, 4, 1), dtype=string)\n          • append=tf.Tensor(shape=(4,), dtype=string)\n          • prepend=None\n    \n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(4, 4, 1), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zHxcRVI3PItJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}